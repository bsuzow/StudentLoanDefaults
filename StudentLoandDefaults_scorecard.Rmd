---
title: "Student Loan Defaults"
author: "Bo Suzow"
date: "July 30, 2018"
output: 
  html_document:
    keep_md: TRUE
---

# Introduction

Student loan debt (SLD) total in the US reached a staggering number in 1.5 trillion dollars, borrowed by 44 million people. It is `r round(1480/620,1)` times larger than the total of credit card debt.  The SLD total in 2008 was 640 billion dollars [which ballooned to 1.2 trillion by 2015](https://www.politifact.com/truth-o-meter/statements/2015/aug/14/jeb-bush/jeb-bush-student-loan-debt-has-doubled-under-obama/).  

While [the return on investment of higher education (HED) is well known and documented] (https://college-education.procon.org/), student loans accumulated for financing higher education are reported as societal issues such as [reasons for divorce](https://www.yahoo.com/amphtml/finance/news/millennial-marriages-crumbling-student-loan-debt-134145853.html), financial dependence on parents, and lack of home ownership observed in Gen-Y.  

In order for a student to be able to pay off HED loans, the loan total should not exceed his/her annual income from gainful employment the HED would provide.  For unfortunate some, this rule of thumb was violated and loan defaults resulted. 

The US Department of Education publishes the College Scorecard data to help the public to make informed decisions about investments in higher education.  The data features large amount of metrics including default rates and is organized by academic year. In this report, we will focus on the 2014-15 scorecard data.  The goals of this report are:

- Explore the data to ascertain some trends the data is telling us.
- Find out strong predictors affecting default rates.
- Build a predictive model for default rates.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

library(dplyr)
library(tidyr)
library(readxl)
```

# Data Load

This data set is a part of a [data bundle](https://ed-public-download.app.cloud.gov/downloads/CollegeScorecard_Raw_Data.zip) published by the US Department of Education.  This analysis utilizes the data pertinent to the 2014-15 academic year cohort (`MERGED2014_15_PP.csv`). The full data documentation is found [here](https://collegescorecard.ed.gov/assets/FullDataDocumentation.pdf).


```{r data_load, cache=TRUE}

# Load the college scorecard data set for academic year 14-15

scorecard1415 <- read.csv("MERGED2014_15_PP.csv",na.strings=c("NULL","PrivacySuppressed"))
scorecard1415 <- tbl_df(scorecard1415)


```

***
# Data Wrangling

## Strategy 1

- Clean up the data set.
    - Select variables relevant to this study.
    - Standardize column names if necessary.
    - Inspect presence of missing value.
    - Determin missing value treatment strategy if applicable.
    - Transform data types appropriately.


## Select relevant variables 

Two issues with the data set are noticed immediately. 

- First, the number of variables/features is overwhelmingly large at 1700+.
- Secondly, many rows have missing values. 

To address the first issue, the [data element list](https://collegescorecard.ed.gov/assets/CollegeScorecardDataDictionary.xlsx) has been reviewed. Using the [data documentation](https://collegescorecard.ed.gov/assets/FullDataDocumentation.pdf) as guidelines, the variables are selected in the following code block:


```{r selectVar1}

sc1415.all <- scorecard1415 %>% select(OPEID6,INSTNM,STABBR,NUMBRANCH,CONTROL,PREDDEG,
                               REGION,
                               LOCALE,LATITUDE,LONGITUDE,CCBASIC,
                               CCUGPROF,CCSIZSET,RELAFFIL,
                               ADM_RATE_ALL,
                               DISTANCEONLY,UGDS,UG,
                               UGDS_WHITE,UGDS_BLACK,UGDS_HISP,UGDS_ASIAN,
                               CURROPER,
                               NPT4_PUB,NPT4_PRIV,
                               NUM4_PUB,NUM4_PRIV,
                               TUITFTE,INEXPFTE,AVGFACSAL,
                               PFTFAC,
                               PCTPELL,
                               C150_4,
                               RET_FT4,
                               PCTFLOAN,
                               UG25ABV,
                               CDR2,
                               CDR3,
                               PAR_ED_PCT_1STGEN,
                               DEP_INC_AVG,
                               IND_INC_AVG,
                               DEBT_MDN,
                               GRAD_DEBT_MDN,
                               WDRAW_DEBT_MDN,
                               FAMINC,
                               MD_FAMINC,
                               POVERTY_RATE,
                               MN_EARN_WNE_P10,
                               MD_EARN_WNE_P10,
                               CDR3_DENOM
)
                               

```


The `CDR3` column reports the default rate. Hence, the observations with missing values in the column cannot be used for this analysis.  They are removed. 

```{r isNA}
 
sc1415 <- sc1415.all %>% filter(!is.na(CDR3))

```

As for missing values, tt's observed that they are rather concentrated on the schools classified as stand alone graduate institutions. Let's remove them from the analysis.

```{r removeGradInst}
sc1415 <- sc1415 %>% filter(PREDDEG!=4)
```

## Missing Values

Even after removing the grad school rows, are there any columns with missiong values?

```{r colWithMVs}

names(sc1415)[colSums(is.na(sc1415))>0]


```

44 of `r ncol(sc1415)` columns still have missing values.  Let's compute their proportions and select those under 10%.

```{r naProportion}
naProportion <- apply(sc1415,2,function(x){sum(is.na(x))/nrow(sc1415)})
naProportion[naProportion<.1]


```

Let's confirm that all `CDR3` and `CDR3_DENOM` values are numeric.

```{r checkCDR3}

!is.numeric(sc1415$CDR3)
!is.numeric(sc1415$CDR3_DENOM)

```

## Variable selection

Now select the variables with less than 10% missing value. Further clean up by eliminating the rows with missing values (Caveat: This is a simpliest approach of treating missing values.  This may have to be revisited in pursuit of a more efficient strategy.)

(Qu: a better way to select the variables of interest without hard coding, but utilizing the output from the `naProportion` code chunk?)

```{r removeAllMVs}
sc1415 <- sc1415 %>% select(OPEID6, INSTNM, STABBR, NUMBRANCH, CONTROL, PREDDEG, REGION,
                             DISTANCEONLY, TUITFTE, INEXPFTE, 
                             PCTPELL, PCTFLOAN, CDR3, PAR_ED_PCT_1STGEN,
                             DEP_INC_AVG, IND_INC_AVG, 
                             DEBT_MDN, GRAD_DEBT_MDN, WDRAW_DEBT_MDN,
                             FAMINC, MD_FAMINC, CDR3_DENOM)

sc1415.net <- sc1415[complete.cases(sc1415),]


names(sc1415)[colSums(is.na(sc1415.net))>0]

```

The total number of rows has reduced from `r nrow(sc1415)` to `r nrow(sc1415.net)`. 
The summary statistics of default rates (`CDR3`) are comparable amongst the three data sets -- with graduate schools present, without grad schools, and without missing values.  We will move ahead with the the `sc1415.net` data frame for the analysis.  Please note that the unclassified institution (`PREDDEG = 0`) have been removed at the missing-value row elimination.

(Qu: Should box plots be added to confirm this point?)

```{r summaryCDR3}

summary(sc1415.all$CDR3)

summary(sc1415$CDR3)

summary(sc1415.net$CDR3)

```

## Strategy 2

Stragegy 1 left us with a few number of numeric variables. A quick exploratory plots show no so strong associations between them and default rates.

Armed with some knowledge Stragety 1 revealed, let's take a different approach:

- Remove all rows with missing `CDR3` values.  It reduces the # of variables from 7100+ to 1700+.
- Remove stand-alone gradudate institutions and those unclassified (`PREDDEG == 0 or 4`).
_ Remove all columns with missing values. 

```{r}
sc1415.cdr3 = scorecard1415 %>% filter(!is.na(CDR3))
sc1415.cdr3 = sc1415.cdr3 %>% filter(!(PREDDEG == 0 | PREDDEG == 4))
sc1415.cdr3 <- sc1415.cdr3[,colSums(is.na(sc1415.cdr3))==0]

```

This results in `r nrow(sc1415.cdr3)` rows and `r ncol(sc1415.cdr3)` columns. This data frame is bigger than one resulted from Strategy 1, its features are mostly reporting fields of study (Classification of Instructional Programs). We will move ahead with the Strategy 1's data frame `sc1415.net`, but keep `sc1415.cdr3` for complimentary data if needed.

***

## Converting to factor variables

Convert `CONTROL`, `PREDDEG`, `DISTANCEONLY`, and `REGION` to factor variables.

```{r facVars}

control_list <- c(1:3)
control_descs <- c("Public",
                  "Private nonprofit",
                  "Private for-profit")

sc1415.net <- sc1415.net %>% mutate(CONTROL = factor(CONTROL,levels=control_list,
                                             labels=control_descs))
# 1	Public
# 2	Private nonprofit
# 3	Private for-profit


preddeg_list <- c(1:3)
preddeg_descs <- c(
                  "Certificate",
                  "Associate's",
                  "Bachelor's"
                  )

sc1415.net <- sc1415.net %>% mutate(PREDDEG = factor(PREDDEG,levels=preddeg_list,
                                             labels=preddeg_descs))

# 0	Not classified	IPEDS  -- not included in the analysis
# 1	Predominantly certificate-degree granting	
# 2	Predominantly associate's-degree granting	
# 3	Predominantly bachelor's-degree granting	
# 4	Entirely graduate-degree granting -- not included in the analysis	


distanceonly_list = c(0:1)
distanceonly_descs = c("Not Online-Ed Only",
                  "Online-Ed Only")

sc1415.net <- sc1415.net %>% mutate(DISTANCEONLY = factor(DISTANCEONLY,levels=distanceonly_list,
                                             labels=distanceonly_descs))

#0	Not distance-education only
#1	Distance-education only


region_list <- c(0:9)
region_descs <- c("U.S. Service Schools",
                 "New England",
                 "Mid East",
                 "Great Lakes",
                 "Plains",
                 "Southeast",
                 "Southwest",
                 "Rocky Mtn",
                 "Far West",
                 "Outlying Areas")

sc1415.net <- sc1415.net %>% mutate(REGION = factor(REGION,levels=region_list,
                                             labels=region_descs))


# 0	U.S. Service Schools	
# 1	New England (CT, ME, MA, NH, RI, VT)		
# 2	Mid East (DE, DC, MD, NJ, NY, PA)		
# 3	Great Lakes (IL, IN, MI, OH, WI)		
# 4	Plains (IA, KS, MN, MO, NE, ND, SD)		
# 5	Southeast (AL, AR, FL, GA, KY, LA, MS, NC, SC, TN, VA, WV)		
# 6	Southwest (AZ, NM, OK, TX)		
# 7	Rocky Mountains (CO, ID, MT, UT, WY)		
# 8	Far West (AK, CA, HI, NV, OR, WA)		
# 9	Outlying Areas (AS, FM, GU, MH, MP, PR, PW, VI)		


```

# Exploratory Data Analysis (WIP)


## Quick Descriptive Statistics

The total number of students who are in repayment as of FYR 2014-15 is `r round(sum(sc1415$CDR3_DENOM)/1000000,1)` million. Of these, `r round(sum(sc1415.net$CDR3_DENOM)/1000000,1)` million are the students from certificate, associate's or bachelor's degree programs.  Their average default rate is `r mean(sc1415.net$CDR3)` with the standard deviation of `r sd(sc1415.net$CDR3)`.

Total count, mean and standard deviation of default rates (`CDR3`) by `CONTROL` - ownership type.

```{r}
table(sc1415.net$CONTROL)
sc1415.net %>% group_by(CONTROL) %>% summarize(mean(CDR3),sd(CDR3))
```

By `PREDDEG`- predominant degree awarded.

```{r}
table(sc1415.net$PREDDEG)
sc1415.net %>% group_by(PREDDEG) %>% summarize(mean(CDR3),sd(CDR3))

```

By `DISTANCEONLY` - whether distance education only or not.

```{r}
table(sc1415.net$DISTANCEONLY)
sc1415.net %>% group_by(DISTANCEONLY) %>% summarize(mean(CDR3),sd(CDR3))
```

By `REGION` - geographical location.

```{r}
table(sc1415.net$REGION)
sc1415.net %>% group_by(REGION) %>% summarize(mean(CDR3),sd(CDR3))
```

Summaries of numerical variables.

```{r}

sc1415.net %>% group_by(CONTROL) %>% summarize(mean(CDR3),sd(CDR3))

```

## Plotting

Let's draw some histograms.


```{r descStatPlots}

ggplot(sc1415.net,aes(x=CDR3)) + 
   geom_histogram(binwidth=.03,alpha=.5) +
   xlab("Default Rate")

ggplot(sc1415.net,aes(x=CDR3, fill=CONTROL)) + 
   geom_histogram(binwidth=.03) +
   facet_grid(CONTROL~.) +
   xlab("Default Rate")

ggplot(sc1415.net,aes(x=CDR3, fill=PREDDEG)) + 
   geom_histogram(binwidth=.03) +
   facet_grid(PREDDEG~.) +
   xlab("Default Rate")

ggplot(sc1415.net,aes(x=CDR3, fill=DISTANCEONLY)) + 
   geom_histogram(binwidth=.03) +
   facet_grid(DISTANCEONLY~.) +
   xlab("Default Rate")

ggplot(sc1415.net,aes(x=CDR3, fill=REGION)) + 
   geom_histogram(binwidth=.03) +
   facet_grid(REGION~.) +
   xlab("Default Rate")



```


## Scatter Plots


#### Percent of Pell Grant vs default rate

```{r}

ggplot(sc1415.net,aes(x=PCTPELL,y=CDR3)) +
   geom_point(alpha=.3, col='Blue') +
   geom_smooth(method="lm", col="black")

```


#### Percent of Federal loan vs default rate

```{r}

ggplot(sc1415.net,aes(x=PCTFLOAN,y=CDR3)) +
   geom_point(alpha=.3, col='green') +
   geom_smooth(method="lm", col="black")

```

#### Average family income of dependent students vs default rate

```{r}

ggplot(sc1415.net,aes(x=DEP_INC_AVG,y=CDR3)) +
   geom_point(alpha=.3, col='blue') +
   geom_smooth(method="lm", col="black")

```


#### Average family income of independent students vs default rate

```{r}

ggplot(sc1415.net,aes(x=IND_INC_AVG,y=CDR3)) +
   geom_point(alpha=.3, col='blue') +
   geom_smooth(method="lm", col="black")

```

#### Median loan amount vs default rate

```{r}

ggplot(sc1415.net,aes(x=DEBT_MDN,y=CDR3)) +
   geom_point(alpha=.3, col='blue') +
   geom_smooth(method="lm", col="black")

```

#### Median family income vs default rate

```{r}

ggplot(sc1415.net,aes(x=MD_FAMINC,y=CDR3)) +
   geom_point(alpha=.3, col='blue') +
   geom_smooth(method="lm", col="black")

```



#### Number of students in cohort vs default rate

```{r}

ggplot(sc1415.net,aes(x=CDR3_DENOM,y=CDR3)) +
   geom_point(alpha=.05, col='blue') +
   geom_smooth(method="lm", col="black")

```

#### Number of students in cohort vs default rate - without outliers

```{r}

ggplot(sc1415.net[sc1415.net$CDR3_DENOM<100000,],aes(x=CDR3_DENOM,y=CDR3)) +
   geom_point(alpha=.05, col='blue') +
   geom_smooth(method="lm", col="black")

```


#### Median debt vs default rate for students who completed by school ownership type

```{r}

# The median debt for students who have completed vs default rate by school ownership

ggplot(sc1415.net,aes(x=GRAD_DEBT_MDN,y=CDR3, col=CONTROL)) +
   geom_point(alpha=.3) +
   facet_grid(CONTROL~.) +
   geom_smooth(col="black", method="lm") +
   xlab("The median debt for students who have completed") +
   ylab("Default Rate") 

```

For public schools, the higher default rates are more concentrated in the lower median debt brackets.  It is interesting to note that median debt has no association with default rate for for-profit private schools.


#### Median debt vs default rate for students who did not complete by school ownership type

```{r}
# The median debt for students who have withdrawn vs default rate by school ownership

ggplot(sc1415.net,aes(y=CDR3,x=WDRAW_DEBT_MDN, col=CONTROL)) +
   geom_point(alpha=.3) +
   facet_grid(CONTROL~.) +
   geom_smooth(col="black", method="lm") +
   xlab("The median debt for students who have not completed") +
   ylab("Default Rate")

```

The same trends are observed regardless of program completion status.

#### First generation vs default rate by school ownership type

```{r}

# Percentage first-generation students vs default rate by school ownership

ggplot(sc1415.net,aes(y=CDR3,x=PAR_ED_PCT_1STGEN, col=CONTROL)) +
   geom_point(alpha=.3) +
   facet_grid(CONTROL~.) +
   geom_smooth(col="black", method="lm") +
   xlab("Percentage first-generation students") +
   ylab("Default Rate")

```

There is a positive correlation between default rate and proportion of students who reported as first generation in getting higher education. For-profit private schools seem to have a higher mean of the proportions. 


#### Federal student oan vs default rate by school ownership type

```{r}

# Percent of all undergraduate students receiving a federal student loan

ggplot(sc1415.net,aes(y=CDR3,x=PCTFLOAN, col=CONTROL)) +
   geom_point(alpha=.3) +
   facet_grid(CONTROL~.) + 
   geom_smooth(col="black", method="lm") +
   xlab("Percent of all UG students receiving a federal student loan") +
   ylab("Default Rate")

```

For-profit private institutions report higher fed loan participation rates. Yet, their default rates don't have any correlation with the participation rates.  

In the following plots facetting based on degree type or region, the correlation between first generation and default rate repeats. Students who completed bachelor's degree programs contributed to higher default rates when facing higher loan debt (positive correlation).

Across regions, simiar regression lines are drawn.  No regions do better or worse when it comes to default rates.


```{r}

# The median debt for students who have completed vs default rate by degree type

ggplot(sc1415.net,aes(y=CDR3,x=GRAD_DEBT_MDN, col=PREDDEG)) +
   geom_point(alpha=.3) +
   facet_grid(PREDDEG~.) +
   geom_smooth(col="black", method="lm") +
   ylab("Default Rate")


# The median debt for students who have withdrawn vs default rate by degree type

ggplot(sc1415.net,aes(y=CDR3,x=WDRAW_DEBT_MDN, col=PREDDEG)) +
   geom_point(alpha=.3) +
   facet_grid(PREDDEG~.) +
   geom_smooth(col="black", method="lm") +
   ylab("Default Rate")


# Percentage first-generation students vs default rate by degree type

# try geom_jitter()


ggplot(sc1415.net,aes(y=CDR3,x=PAR_ED_PCT_1STGEN, col=PREDDEG)) +
   geom_point(alpha=.3) +
   facet_grid(PREDDEG~.) +
   geom_smooth(col="black", method="lm") + 
   ylab("Default Rate")



```


Numeric variables vs default rate by region.  

```{r}

# The median debt for students who have completed vs default rate by region

ggplot(sc1415.net,aes(y=CDR3,x=GRAD_DEBT_MDN, col=REGION)) +
   geom_point(alpha=.3) +
   facet_grid(REGION~.) +
   geom_smooth(col="black", method="lm")

# The median debt for students who have withdrawn vs default rate by region

ggplot(sc1415.net,aes(y=CDR3,x=WDRAW_DEBT_MDN, col=REGION)) +
   geom_point(alpha=.3) +
   facet_grid(REGION~.) +
   geom_smooth(col="black", method="lm")

# Percentage first-generation students vs default rate by region

# try geom_jitter()


ggplot(sc1415.net,aes(y=CDR3,x=PAR_ED_PCT_1STGEN, col=REGION)) +
   geom_point(alpha=.3) +
   facet_grid(REGION~.) +
   geom_smooth(col="black", method="lm")


```


## Categorical Variable Conversion to Dummy Variables

Before building modeling, categorical variables need to be converted to dummy variables. `CONTROL`, `PREDDEG`, and `REGION` will be converted. `DISTANCEONLY` has been dropped as its values are highly skewed. 

```{r}

library(caret)

dummies <- dummyVars("~ CONTROL + PREDDEG + REGION", data=sc1415.net,fullRank=TRUE)
dummies <- data.frame(predict(dummies,newdata=sc1415.net))
sc1415.final <- as.data.frame(cbind(sc1415.net,dummies))

# remove variables unused in modeling building

sc1415.final$OPEID6 <-  NULL
sc1415.final$STABBR <-  NULL
sc1415.final$INSTNM <-  NULL

sc1415.final$CONTROL <- NULL
sc1415.final$REGION  <- NULL
sc1415.final$PREDDEG <- NULL
sc1415.final$DISTANCEONLY <- NULL

```

## Predictive Model Building

Now, the `sc1415.final` data frame is all set for building models.  It consists of `r nrow(sc1415.final)` observations and `r ncol(sc1415.final)-1` independent variables.  The `CDR3` is the outcome variable.  The goal is to predict student loan default rates.

Let's split the data frame to training and test sets.

```{r}

library(caTools)
set.seed(100)
split_vec <- sample.split(sc1415.final$CDR3,SplitRatio=.75)
Train <- sc1415.final[split_vec,]
Test <- sc1415.final[!(split_vec),]


```


### Model 1 - Linear Regression

#### Full MOdel 
In this modeling, all independent variables are thrown in. Uninfluential variables are eliminated with the `stepAIC()` function from the `MASS` package.  

```{r}
lm1 <- lm(CDR3~.,data=Train)
summary(lm1)

library(MASS)
step.model1 <- stepAIC(lm1, direction = "both", 
                      trace = FALSE)
summary(step.model1)

```
It reduces the number of predictors to `r step.model1$rank` from `r ncol(sc1415.final)`.

Alternatively, let's try the `regsubsets()` that provides the tuning parameter `nvmax` for the number of predictors. In order to optimize `nvmax`, we can use k-fold cross-validation. Click [here](http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/) for details and an example.

```{r}
set.seed(100)

k = 10
train.control <- trainControl(method = "cv", number = k)

nvmaxCV <- train(CDR3 ~., data = sc1415.final,
                    method = "leapBackward", 
                    tuneGrid = data.frame(nvmax = 1:19),
                    trControl = train.control
                    )
nvmaxCV$results

```

The # of predictors recommended is `r nvmaxCV$bestTune`.  The list of the selected predictors is as follows:

```{r}
names(coef(nvmaxCV$finalModel,13))

```

Let's build another model using these variables.

```{r}

lm2 <- lm(CDR3~INEXPFTE+PAR_ED_PCT_1STGEN+DEP_INC_AVG+IND_INC_AVG+
          DEBT_MDN+GRAD_DEBT_MDN+CONTROL.Private.nonprofit+CONTROL.Private.for.profit+
          PREDDEG.Bachelor.s+REGION.Plains+REGION.Southeast+REGION.Southwest+REGION.Rocky.Mtn,
          data=Train)

summary(lm2)
```

The RMSEs from the three models above are:

```{r}

# Full Model - 28 variables
sqrt(sum(lm1$residuals^2)/nrow(Train))

# Model with 19 variables
sqrt(sum(step.model1$residuals^2)/nrow(Train))

# Model with 13 variables
sqrt(sum(lm2$residuals^2)/nrow(Train))

```

While the RMSE of the full model is the lowest of the three, the delta is quite small. Therefore, the `lm2` model will be used for prediction.

The following plot shows that the residuals bounce around the X-axis, confirming the validity of the model.

```{r}

#plot(lm2$residuals)

ggplot(data=Train,aes(x=as.numeric(row.names(Train)),y=lm2$residuals)) + geom_point(alpha=.2) +
   xlab("Training Set Observation Index") +
   ylab("Residual")

```

```{r}

# Prediction
lm2.pred <- predict(lm2, newdata=Test)
residualTest <- (lm2.pred - Test$CDR3)
# RMSE
sqrt(sum(residualTest^2)/nrow(Test))

```

The RMSE at `r sqrt(sum(residualTest^2)/nrow(Test))` is lower than that of the training set. 


### Model 2 - Classification and Regression Tree (CART)


```{r}


library(caret)
library(e1071)



```

```

### Model 3 - Random Forests (RF)

```{r}

```



